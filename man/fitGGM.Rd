% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fitGGM.R
\name{fitGGM}
\alias{fitGGM}
\title{Estimate an undirected GGM by fast node-wise penalized regression with FDR control}
\usage{
fitGGM(
  X,
  standardize = FALSE,
  nsignals = 1000,
  nlambda = 30,
  lambda.min = NULL,
  lambda.max = NULL,
  alpha = 1,
  sym = "or",
  qfdr = 0.1,
  r1 = 0.4,
  corX = NULL,
  cor.thres = NULL,
  ncores = max(1, parallel::detectCores(logical = TRUE) - 1)
)
}
\arguments{
\item{X}{Numeric matrix of size \eqn{N \times M} (samples \eqn{\times} variables).
Columns are the nodes of the GGM.}

\item{standardize}{Logical flag for standardization of the columns of \code{X},
prior to fitting the model sequence. Default: \code{FALSE}.}

\item{nsignals}{Rough upper bound on the number of non-nulls used to set the
\eqn{\lambda} range when \code{lambda.min} or \code{lambda.max} is \code{NULL}.
Default \code{1000}.}

\item{nlambda}{Length of the penalty path. Default \code{30}.}

\item{lambda.min, lambda.max}{Optional numeric endpoints of the \eqn{\lambda} path.
If either is \code{NULL}, the range is computed by internal heuristics
\code{lambda.GGM.lower}/\code{lambda.GGM.upper} given \code{N}, \code{M},
\code{alpha}, and \code{nsignals}.}

\item{alpha}{Elastic-net mixing parameter passed to \pkg{glmnet}:
\code{alpha = 1} is lasso; \code{0 < alpha < 1} is elastic net.
Default \code{1}.}

\item{sym}{Symmetrization rule for the undirected graph constructed from
directed node-wise fits; \code{'or'} (union, default) or \code{'and'}
(intersection).}

\item{qfdr}{Target FDR level used to pick the optimal \eqn{\lambda} along the
path. Default \code{0.1}.}

\item{r1}{Threshold (in absolute correlation) used to thin highly-correlated
detections within a node-wise fit and to define the exclusion set when
computing bias-adjusted false-positive counts. Default \code{0.4}.}

\item{corX}{Optional precomputed correlation matrix of \code{X} (diagonal will
be zeroed). If \code{NULL}, it is computed internally. Supplying it can save time
when calling the function repeatedly on the same data. Default \code{NULL}.}

\item{cor.thres}{Optional correlation screening threshold used to form
per-node candidate sets; if \code{NULL}, set to \code{max(0.2, r1 - 0.2)}.}

\item{ncores}{Number of CPU cores for parallel node-wise regressions. Default
\code{max(1, parallel::detectCores(logical = TRUE) - 1)}.}
}
\value{
A list with components:
\item{lambda}{Numeric vector of \eqn{\lambda} values (length \code{nlambda}).}
\item{opt.index}{Index of the selected \eqn{\lambda} based on the FDR curve.}
\item{signals}{Length-\code{nlambda} list of sparse \eqn{M \times M} matrices
containing directed node-wise coefficients at each \eqn{\lambda} after
correlation thinning.}
\item{dfres}{Data frame with columns \code{lambda}, \code{exp.false},
\code{detections}, and \code{fdr}.}
\item{beta.fit}{Sparse \eqn{M \times M} matrix of coefficients at the selected
\eqn{\lambda}.}
\item{path.fit}{Absolute-value adjacency used to form the undirected graph by
\code{sym}.}
}
\description{
Fast bias-corrected node-wise regression for Gaussian graphical models
}
\details{
Estimate a Gaussian Graphical Model (GGM) via node-wise penalized regression
(lasso / elastic net) with a fast, bias-corrected procedure for counting
expected false positives and selecting \eqn{\lambda} by an estimated FDR curve.
Compared to a naïve implementation, this function caches correlations,
vectorizes variance updates, and assembles coefficient paths sparsely for speed.

\strong{Algorithm (high level):}
\enumerate{
\item For each node \eqn{i}, regress \eqn{X_i} on the remaining columns \eqn{X_{-i}}
using \pkg{glmnet} over a path of \eqn{\lambda} values (\code{alpha} controls
lasso vs elastic net).
\item Within each \eqn{\lambda}, thin pairs of selected predictors whose absolute
correlation exceeds \code{r1} by keeping the predictor with the larger
absolute coefficient.
\item Split predictors into an “uncorrelated” pool and a “correlated” pool
(based on \code{cor.thres}). For each pool, compute the expected number of
false positives using Gaussian tail bounds. For the correlated pool, apply
a bias term \eqn{\mu} to the tails:
\itemize{
\item Lasso: \eqn{\mu_z=\lambda\,\mathrm{sign}(\beta_t)\,\mathrm{cor}(z,t)}.
\item Elastic net (\eqn{0<\alpha<1}): \eqn{\delta_t=\frac{(1+\hat b_{OLS,t})\,\alpha\lambda}{1+\alpha\lambda}},\;
\eqn{\mu_z=\delta_t\,\mathrm{cor}(z,t)}, where \eqn{\hat b_{OLS,t}} is a
simple OLS update using the current residual (fast rank-1 formulas).
}
\item Sum the expected false positives across nodes to get \code{exp.false} at
each \eqn{\lambda}, and compute \code{fdr = exp.false / max(1, detections)}.
\item Choose the largest \eqn{\lambda} such that the estimated FDR does not exceed
\code{qfdr}, and build the undirected adjacency by \code{sym}.
}

The implementation uses cached adjacency lists from \code{corX}, vectorized
variance/SD updates for rank-1 changes in residuals, and sparse triplet
assembly of coefficient matrices to reduce memory traffic.
}
\author{
Samuel Anyaso-Samuel
}
